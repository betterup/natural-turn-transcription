{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a6d886-e361-4783-aa53-ddd455906c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from io import StringIO\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transcription.text import collapse_transcript_turns\n",
    "from transcription.transcript_config import (\n",
    "    Transcript, \n",
    "    TranscriptConfig, \n",
    "    TranscriptConfigVersion, \n",
    "    BACKCHANNEL_CUES, \n",
    "    NOT_BACKCHANNEL_CUES, \n",
    "    baseline, \n",
    "    natural_turn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff789da-98f3-42f2-b87b-1b34c5601e2f",
   "metadata": {},
   "source": [
    "#### Step 1: Get list of conversation IDs from zip file  \n",
    "This step pulls CANDOR conversation IDs from `data/aws-2024-candor-raw-api.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691f121d-305f-4876-a609-527d6d10db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to zip archive of CANDOR corpus AWS Transcribe JSON files\n",
    "zip_file_path = 'data/aws-2024-candor-raw-api.zip'\n",
    "\n",
    "# Assuming file naming convention is unchanged\n",
    "# Example: 0020a0c5-1658-4747-99c1-2839e736b481--transcribe--Jan-2024.json\n",
    "# Split on \"--\" and take the first split segment to get conversation ID\n",
    "\n",
    "conversation_ids = []\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as stt_zip:\n",
    "    # Get a list of file names within the ZIP file\n",
    "    for filename in stt_zip.namelist():\n",
    "        # Extract the conversation_id from the filename\n",
    "        conversation_id = filename.split('--')[0]\n",
    "        # The filename may include a path, so we split on '/' and take the last part\n",
    "        conversation_id = conversation_id.split('/')[-1]\n",
    "        conversation_ids.append(conversation_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6bac62-860e-45aa-9dbf-113d557bda80",
   "metadata": {},
   "source": [
    "#### Step 2: Class definition for `TranscriptFormatter()`  \n",
    "Note: This class is exposed for advanced users who want to make tweaks to functionality.  \n",
    "If you just want to create transcripts using the default data and settings, do not change anything in this block. Simply run it and continue to the next block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b1f681-302d-4cd7-9fed-ae317ca993ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptFormatter(object):\n",
    "    \"\"\"Converts raw JSON from AWS speech-to-text API output into a formatted transcript.  \n",
    "        Steps:  \n",
    "            1. Initialize TranscriptFormatter() instance with a conversation ID.  \n",
    "            2. Create `baseline` transcript (as Pandas data frame) from AWS Transcribe raw API JSON output.  \n",
    "            3. Create `natural_turn` transcript and edit history data frame from `baseline`.  \n",
    "            4. (optional) Save transcript data frames (object attrs: baseline, edit_history, transcript) to CSV\n",
    "\n",
    "        Notes:\n",
    "            - Ensure `path` definitions are updated to match local environment  \n",
    "            - If using custom (non-CANDOR) metadata to link channels <-> speaker IDs, see JSON formatting \n",
    "              requirements in replace_speaker_channel_with_user_id() comments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        conversation_id,\n",
    "        data_dir,\n",
    "        save_dir,\n",
    "        channel_speaker_map=None,\n",
    "        stt_model='aws',\n",
    "    ):\n",
    "        self.conversation_id = conversation_id\n",
    "        self.channel_speaker_map = channel_speaker_map\n",
    "        self.stt_model = stt_model\n",
    "        # adjust paths to match local directory structure and filename convention\n",
    "        self.stt_path = f\"{data_dir}/aws-2024-candor-raw-api/{conversation_id}--transcribe--Jan-2024.json\"\n",
    "        self.metadata_path = f'{data_dir}/candor_metadata_files/{conversation_id}_metadata.json'\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "    def construct_conversation_transcript(self):\n",
    "        \"\"\"Parses a two-channel AWS Transcribe response into a simple time-ordered data structure.\n",
    "    \n",
    "        Returns: dict\n",
    "        \"\"\"\n",
    "        response_data = json.load(open(self.stt_path, 'r'))\n",
    "        \n",
    "        def _annotate_two_channel_chunks(channel_data, speaker_label):\n",
    "            \"\"\"Utility for parsing multi speaker Amazon Transcribe result. \n",
    "               Creates keys for \"speaker,\" \"start_time,\" and \"end_time.\"\n",
    "    \n",
    "            Returns: dict\n",
    "            \"\"\"\n",
    "            most_recent_start = 0\n",
    "            most_recent_end = 0\n",
    "            for i, chunk in enumerate(channel_data):\n",
    "                # keep track of most recent start/end timestamps\n",
    "                # if we hit a punctuation mark, assign the most recent start/end as that mark's timestamps\n",
    "                if \"start_time\" in chunk.keys():\n",
    "                    most_recent_start = float(chunk['start_time'])\n",
    "                    most_recent_end = float(chunk['end_time']) # if there is start, there is always an end\n",
    "                channel_data[i][\"speaker\"] = speaker_label\n",
    "                if channel_data[i][\"type\"] == \"punctuation\":\n",
    "                    channel_data[i][\"start_time\"] = most_recent_start\n",
    "                    channel_data[i][\"end_time\"] = most_recent_end\n",
    "            return channel_data\n",
    "    \n",
    "        def _parse_two_channel_transcript(combined_annotated_data):\n",
    "            \"\"\"Converts word-level data into utterance-level data.\n",
    "    \n",
    "            Returns: list\n",
    "            \"\"\"\n",
    "            lines = []\n",
    "            line = []\n",
    "            line_confidences = []\n",
    "            for i, chunk in enumerate(combined_annotated_data):\n",
    "                segment = chunk[\"alternatives\"][0][\"content\"]\n",
    "                confidence = float(chunk[\"alternatives\"][0][\"confidence\"])\n",
    "                if i == 0:\n",
    "                    line.append(segment)\n",
    "                    line_confidences.append(confidence)\n",
    "                    line_start = chunk[\"start_time\"]\n",
    "    \n",
    "                elif chunk[\"speaker\"] == combined_annotated_data[i - 1][\"speaker\"]:\n",
    "                    if chunk[\"type\"] == \"punctuation\":\n",
    "                        line[-1] += segment\n",
    "                        line_confidences.append(confidence)\n",
    "                    else:\n",
    "                        line.append(segment)\n",
    "                        line_confidences.append(confidence)\n",
    "                else:\n",
    "    \n",
    "                    # wrap up current line\n",
    "                    line_speaker = combined_annotated_data[i - 1][\"speaker\"]\n",
    "                    labeled_line = \" \".join(line)\n",
    "                    line_end = combined_annotated_data[i - 1][\"end_time\"]\n",
    "                    lines.append(\n",
    "                        {\n",
    "                            \"speaker\": line_speaker,\n",
    "                            \"start\": line_start,\n",
    "                            \"stop\": line_end,\n",
    "                            \"utterance\": labeled_line,\n",
    "                            \"confidence\": line_confidences,\n",
    "                        }\n",
    "                    )\n",
    "    \n",
    "                    # initialize next line\n",
    "                    line_start = chunk[\"start_time\"]\n",
    "                    line = []\n",
    "                    line_confidences = []\n",
    "                    line.append(segment)\n",
    "                    line_confidences.append(confidence)\n",
    "    \n",
    "            # Add an id to each turn\n",
    "            for ind, line in enumerate(lines):\n",
    "                line[\"turn_id\"] = ind\n",
    "    \n",
    "            return lines\n",
    "    \n",
    "        channel_0 = response_data[\"results\"][\"channel_labels\"][\"channels\"][0][\"items\"]\n",
    "        channel_1 = response_data[\"results\"][\"channel_labels\"][\"channels\"][1][\"items\"]\n",
    "    \n",
    "        # Channel 0 is left, channel 1 is right\n",
    "        if self.channel_speaker_map:\n",
    "            speaker_0_id = self.channel_speaker_map[\"L\"]\n",
    "            speaker_1_id = self.channel_speaker_map[\"R\"]\n",
    "        else:\n",
    "            speaker_0_id = \"L\"\n",
    "            speaker_1_id = \"R\"\n",
    "    \n",
    "        annotated_c0 = _annotate_two_channel_chunks(channel_0, speaker_0_id)\n",
    "        annotated_c1 = _annotate_two_channel_chunks(channel_1, speaker_1_id)\n",
    "    \n",
    "        combined_annotated = annotated_c0 + annotated_c1\n",
    "        combined_annotated = sorted(combined_annotated, key=lambda chunk: float(chunk[\"start_time\"]))\n",
    "    \n",
    "        transcript = _parse_two_channel_transcript(combined_annotated)\n",
    "        transcript_dict = {\"transcript\": transcript}\n",
    "    \n",
    "        return transcript_dict\n",
    "\n",
    "    def json_to_baseline_df(self, json_transcript):\n",
    "        TRANSCRIPT_COLUMNS = (\"speaker\", \"start\", \"stop\", \"utterance\", \"confidence\")\n",
    "        TRANSCRIPT_DTYPES = (str, np.float64, np.float64, str, object)\n",
    "        \n",
    "        df = pd.DataFrame.from_records(json_transcript['transcript'], index=\"turn_id\")\n",
    "        df = self.replace_speaker_channel_with_user_id(df)\n",
    "        \n",
    "        assert set(df.columns) == set(TRANSCRIPT_COLUMNS)\n",
    "        \n",
    "        for c, d in zip(TRANSCRIPT_COLUMNS, TRANSCRIPT_DTYPES):\n",
    "            df[c] = df[c].astype(d)\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(\"Conversation is empty. Did you pass a dict or list?\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def baseline_to_natural_turn(self, baseline_df, config):\n",
    "        return collapse_transcript_turns(Transcript(baseline_df, config))\n",
    "\n",
    "    def save_transcripts_to_local(self, transcript_obj, model_label):\n",
    "        # update paths to reflect local save file directory\n",
    "        baseline_filename = f'{self.save_dir}/{self.conversation_id}_baseline.csv'\n",
    "        natural_turn_filename = f'{self.save_dir}/{self.conversation_id}_{model_label}.csv'\n",
    "        edit_history_filename = f'{self.save_dir}/{self.conversation_id}_{model_label}_edit-history.csv'\n",
    "\n",
    "        transcript_obj.baseline.to_csv(baseline_filename)\n",
    "        transcript_obj.transcript.to_csv(natural_turn_filename)\n",
    "        transcript_obj.edit_history.to_csv(edit_history_filename)\n",
    "        \n",
    "    def replace_speaker_channel_with_user_id(self, df):\n",
    "        \"\"\"Use any JSON file with the following structure to map stereo channels (L/R) to speaker IDs:\n",
    "            metadata: full JSON object\n",
    "            metadata['speakers']: 'speakers' key is a list, each entry is a dict with 'channel' and 'user_id' keys\n",
    "            metadata['speakers'][0]['channel']: takes values 'L' or 'R'\n",
    "            metadata['speakers'][0]['user_id']: unique identifier for a speaker\n",
    "        \"\"\"\n",
    "        metadata = json.load(open(self.metadata_path, 'r'))\n",
    "        \n",
    "        # Create mapping from channel to user_id\n",
    "        speaker_mapping = {speaker['channel']: speaker['user_id'] for speaker in metadata['speakers']}\n",
    "        \n",
    "        # Replace R/L 'speaker' values with user_id values\n",
    "        df['speaker'] = df['speaker'].map(speaker_mapping)\n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6073a0-a0f3-42fd-b3f4-a869c08cf7e5",
   "metadata": {},
   "source": [
    "#### Step 3: Generate `NaturalTurn` transcripts from AWS Transcribe API output  \n",
    "This code creates a `TranscriptFormatter` object for each CANDOR conversation, creates `baseline` and `natural_turn` transcripts as Pandas data frames, and saves the resulting CSVs.  \n",
    "\n",
    "*Note: The following two blocks - creating transcripts and combining them into a single data frame - can be combined, without the middle step of saving each conversation's transcript files to disk.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99bfe3e7-5a11-4149-bfc8-c3342cf8dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change conversation_ids to a subset to run a short test, i.e. use conversation_ids[:10] instead\n",
    "conversation_ids_to_process = conversation_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f286bfe-acd8-4417-8b4a-8eb601a87cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6cc56ecc-d29c-4bb3-bbd9-c67236c15b0c processing...\n",
      "afa4d802-a9ed-4b0b-a607-b5f16d899275 processing...\n",
      "42d99fff-daee-41bc-ba4a-55b6a787e51d processing...\n",
      "473435df-b97f-4c9f-a8e2-8e3fc66a8902 processing...\n",
      "f5ced37a-1596-4e77-ab1d-dae5e084384d processing...\n",
      "a003874c-1d39-4924-857f-94a865951ae9 processing...\n",
      "7fc59ebb-a980-4df1-9d39-f15ae25f3f27 processing...\n",
      "e12fed95-8f11-4255-b8c7-f5c0346b8e59 processing...\n",
      "cc7a5173-9c79-4773-83dc-0d9177bcc524 processing...\n",
      "5d7dc5a5-8dbe-4fb0-bf59-2d53f0ce3b65 processing...\n"
     ]
    }
   ],
   "source": [
    "turn_model = natural_turn_1000\n",
    "\n",
    "for conversation_id in conversation_ids_to_process:\n",
    "    print(f'{conversation_id} processing...')\n",
    "    formatter = TranscriptFormatter(\n",
    "        conversation_id=conversation_id, \n",
    "        data_dir=\"data/\",\n",
    "        save_dir=\"data/new_transcripts\"\n",
    "    )\n",
    "    try:\n",
    "        formatted_json = formatter.construct_conversation_transcript()\n",
    "    except Exception as e:\n",
    "        print(f'Error for convo {conversation_id}: {str(e)}')\n",
    "        continue\n",
    "        \n",
    "    baseline_df = formatter.json_to_baseline_df(formatted_json)\n",
    "    transcript_obj = formatter.baseline_to_natural_turn(baseline_df, config=turn_model)\n",
    "    \n",
    "    # save files\n",
    "    # adjust model_label as needed. here we use the natural_turn max_pause setting to disambiguate model variants.\n",
    "    max_pause = int(turn_model.max_pause * 1000) # max_pause to milliseconds\n",
    "    model_label = f'natural_turn-{max_pause}'\n",
    "    formatter.save_transcripts_to_local(transcript_obj, model_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0a5ed-beee-4ea2-a38f-5aee5721e22f",
   "metadata": {},
   "source": [
    "#### (optional) Step 4: Concat all natural_turns transcripts into a single data frame, save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6806e354-616d-44ea-9ef3-5689f3e16ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_transcripts_from_local(conversation_ids, max_pause, file_path_template):\n",
    "    \"\"\"Convenience function to concatenate all processed transcripts into a single Pandas data frame.\"\"\"\n",
    "    all_dfs = []\n",
    "    for i, conversation_id in enumerate(conversation_ids):\n",
    "        csv_path = file_path_template.format(conversation_id=conversation_id, max_pause=max_pause)\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df['conversation_id'] = conversation_id\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"File not found: {csv_path}\")\n",
    "            print(str(e))\n",
    "    concatenated_df = pd.concat(all_dfs, axis=0, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Usage \n",
    "\n",
    "# Notes: \n",
    "#  - Adjust file_path_template to concatenate baseline or edit_history instead of NT transcripts\n",
    "#  - Adjust save_path to change save location for concatenated CSV\n",
    "max_pause = 1500\n",
    "file_path_template = 'data/new_transcripts/{conversation_id}_natural_turn-{max_pause}.csv'\n",
    "save_path = f'data/aws-2024-natural_turn-{max_pause}--candor.csv'\n",
    "natural_turn_df = concatenate_transcripts_from_local(conversation_ids_to_process, max_pause, file_path_template)\n",
    "natural_turn_df.to_csv(save_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef6e2f-09be-426d-8ef0-b6c42151bcbd",
   "metadata": {},
   "source": [
    "#### Appendix: Create a custom turn segmentation model with `TranscriptConfig()`  \n",
    "This section demonstrates how to create a custom turn model via initializing a `TranscriptConfig` object.  \n",
    "\n",
    "We define `natural_turn_1000`, a version of the `NaturalTurn` transformer with `max_pause` set to 1.0s (1000ms) instead of the default 1.5s max pause length.  \n",
    "See **transcription/transcript_config.py** for full model and parameter specifications.    \n",
    "\n",
    " To use this new model:  \n",
    " * Go to the **Generate `NaturalTurn` transcripts** code block.\n",
    " * Change `turn_model = natural_turn` to `turn_model = natural_turn_1000`.\n",
    " * Re-run the code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e7dba1-b2f4-470a-9ef9-dc9f9aff53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "natural_turn_1000 = TranscriptConfig(\n",
    "    version = TranscriptConfigVersion.V2,\n",
    "    \n",
    "    token_confidence_threshold=0.6,\n",
    "    include_token_confidence=True,\n",
    "    exclude_underconfident_utterances=True,\n",
    "    remove_banned_tokens=True,\n",
    "    remove_suspicious_tokens=True,\n",
    "    \n",
    "    banned_tokens=[],\n",
    "    suspicious_tokens=[],\n",
    "    \n",
    "    flag_underconfident_tokens=True,\n",
    "    mask_underconfident_tokens=False,\n",
    "    \n",
    "    label_turns=True,\n",
    "    combine_secondary_turns=True,\n",
    "    pivot_secondary_turns=False, \n",
    "    \n",
    "    collapse_short_pauses=True,\n",
    "    max_pause=1.0,              # <-- change max_pause from 1.5 to 1.0\n",
    "    \n",
    "    backchannel_word_max=3,\n",
    "    backchannel_proportion=0.5,\n",
    "    \n",
    "    backchannel_cues=BACKCHANNEL_CUES,\n",
    "    not_backchannel_cues=NOT_BACKCHANNEL_CUES,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ac9c3-d937-4f6e-a811-e26c7bcd3e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
