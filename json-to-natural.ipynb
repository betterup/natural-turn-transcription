{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a6d886-e361-4783-aa53-ddd455906c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transcription.text import collapse_transcript_turns\n",
    "from transcription.transcript_config import Transcript, TranscriptConfig, baseline, natural_turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691f121d-305f-4876-a609-527d6d10db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify path to zip archive of CANDOR corpus AWS Transcribe JSON files\n",
    "zip_file_path = 'data/aws-2024-candor-raw-api.zip'\n",
    "\n",
    "# Assuming file naming convention is unchanged\n",
    "# Example: 0020a0c5-1658-4747-99c1-2839e736b481--transcribe--Jan-2024.json\n",
    "# Split on \"--\" and take the first split segment to get conversation ID\n",
    "\n",
    "conversation_ids = []\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as stt_zip:\n",
    "    # Get a list of file names within the ZIP file\n",
    "    for filename in stt_zip.namelist():\n",
    "        # Extract the conversation_id from the filename\n",
    "        conversation_id = filename.split('--')[0]\n",
    "        # The filename may include a path, so we split on '/' and take the last part\n",
    "        conversation_id = conversation_id.split('/')[-1]\n",
    "        conversation_ids.append(conversation_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0b1f681-302d-4cd7-9fed-ae317ca993ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptFormatter(object):\n",
    "    \"\"\"Converts raw JSON from AWS speech-to-text API output into a formatted transcript.  \n",
    "        Steps:  \n",
    "            1. Initialize TranscriptFormatter() instance with a conversation ID.  \n",
    "            2. Create `baseline` transcript (as Pandas data frame) from AWS Transcribe raw API JSON output.  \n",
    "            3. Create `natural_turn` transcript and edit history data frame from `baseline`.  \n",
    "            4. (optional) Save transcript data frames (object attrs: baseline, edit_history, transcript) to CSV\n",
    "\n",
    "        Notes:\n",
    "            - Ensure `path` definitions are updated to match local environment  \n",
    "            - If using custom (non-CANDOR) metadata to link channels <-> speaker IDs, see JSON formatting \n",
    "              requirements in replace_speaker_channel_with_user_id() comments\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        conversation_id,\n",
    "        save_dir,\n",
    "        channel_speaker_map=None,\n",
    "        stt_model='aws', # Deepgram parser not yet integrated\n",
    "    ):\n",
    "        self.conversation_id = conversation_id\n",
    "        self.channel_speaker_map = channel_speaker_map\n",
    "        self.stt_model = stt_model\n",
    "        # adjust paths to match local directory structure and filename convention\n",
    "        self.stt_path = f\"data/aws-2024-candor-raw-api/{conversation_id}--transcribe--Jan-2024.json\"\n",
    "        self.metadata_path = f'data/candor_metadata_files/{conversation_id}_metadata.json'\n",
    "        self.save_dir = save_dir\n",
    "        \n",
    "    def construct_conversation_transcript(self):\n",
    "        \"\"\"Parses a two-channel AWS Transcribe response into a simple time-ordered data structure.\n",
    "    \n",
    "        Returns: dict\n",
    "        \"\"\"\n",
    "        response_data = json.load(open(self.stt_path, 'r'))\n",
    "        \n",
    "        def _annotate_two_channel_chunks(channel_data, speaker_label):\n",
    "            \"\"\"Utility for parsing multi speaker Amazon Transcribe result. \n",
    "               Creates keys for \"speaker,\" \"start_time,\" and \"end_time.\"\n",
    "    \n",
    "            Returns: dict\n",
    "            \"\"\"\n",
    "            most_recent_start = 0\n",
    "            most_recent_end = 0\n",
    "            for i, chunk in enumerate(channel_data):\n",
    "                # keep track of most recent start/end timestamps\n",
    "                # if we hit a punctuation mark, assign the most recent start/end as that mark's timestamps\n",
    "                if \"start_time\" in chunk.keys():\n",
    "                    most_recent_start = float(chunk['start_time'])\n",
    "                    most_recent_end = float(chunk['end_time']) # if there is start, there is always an end\n",
    "                channel_data[i][\"speaker\"] = speaker_label\n",
    "                if channel_data[i][\"type\"] == \"punctuation\":\n",
    "                    channel_data[i][\"start_time\"] = most_recent_start\n",
    "                    channel_data[i][\"end_time\"] = most_recent_end\n",
    "            return channel_data\n",
    "    \n",
    "        def _parse_two_channel_transcript(combined_annotated_data):\n",
    "            \"\"\"Converts word-level data into utterance-level data.\n",
    "    \n",
    "            Returns: list\n",
    "            \"\"\"\n",
    "            lines = []\n",
    "            line = []\n",
    "            line_confidences = []\n",
    "            for i, chunk in enumerate(combined_annotated_data):\n",
    "                segment = chunk[\"alternatives\"][0][\"content\"]\n",
    "                confidence = float(chunk[\"alternatives\"][0][\"confidence\"])\n",
    "                if i == 0:\n",
    "                    line.append(segment)\n",
    "                    line_confidences.append(confidence)\n",
    "                    line_start = chunk[\"start_time\"]\n",
    "    \n",
    "                elif chunk[\"speaker\"] == combined_annotated_data[i - 1][\"speaker\"]:\n",
    "                    if chunk[\"type\"] == \"punctuation\":\n",
    "                        line[-1] += segment\n",
    "                        line_confidences.append(confidence)\n",
    "                    else:\n",
    "                        line.append(segment)\n",
    "                        line_confidences.append(confidence)\n",
    "                else:\n",
    "    \n",
    "                    # wrap up current line\n",
    "                    line_speaker = combined_annotated_data[i - 1][\"speaker\"]\n",
    "                    labeled_line = \" \".join(line)\n",
    "                    line_end = combined_annotated_data[i - 1][\"end_time\"]\n",
    "                    lines.append(\n",
    "                        {\n",
    "                            \"speaker\": line_speaker,\n",
    "                            \"start\": line_start,\n",
    "                            \"stop\": line_end,\n",
    "                            \"utterance\": labeled_line,\n",
    "                            \"confidence\": line_confidences,\n",
    "                        }\n",
    "                    )\n",
    "    \n",
    "                    # initialize next line\n",
    "                    line_start = chunk[\"start_time\"]\n",
    "                    line = []\n",
    "                    line_confidences = []\n",
    "                    line.append(segment)\n",
    "                    line_confidences.append(confidence)\n",
    "    \n",
    "            # Add an id to each turn\n",
    "            for ind, line in enumerate(lines):\n",
    "                line[\"turn_id\"] = ind\n",
    "    \n",
    "            return lines\n",
    "    \n",
    "        channel_0 = response_data[\"results\"][\"channel_labels\"][\"channels\"][0][\"items\"]\n",
    "        channel_1 = response_data[\"results\"][\"channel_labels\"][\"channels\"][1][\"items\"]\n",
    "    \n",
    "        # Channel 0 is left, channel 1 is right\n",
    "        if self.channel_speaker_map:\n",
    "            speaker_0_id = self.channel_speaker_map[\"L\"]\n",
    "            speaker_1_id = self.channel_speaker_map[\"R\"]\n",
    "        else:\n",
    "            speaker_0_id = \"L\"\n",
    "            speaker_1_id = \"R\"\n",
    "    \n",
    "        annotated_c0 = _annotate_two_channel_chunks(channel_0, speaker_0_id)\n",
    "        annotated_c1 = _annotate_two_channel_chunks(channel_1, speaker_1_id)\n",
    "    \n",
    "        combined_annotated = annotated_c0 + annotated_c1\n",
    "        combined_annotated = sorted(combined_annotated, key=lambda chunk: float(chunk[\"start_time\"]))\n",
    "    \n",
    "        transcript = _parse_two_channel_transcript(combined_annotated)\n",
    "        transcript_dict = {\"transcript\": transcript}\n",
    "    \n",
    "        return transcript_dict\n",
    "\n",
    "    def json_to_baseline_df(self, json_transcript):\n",
    "        TRANSCRIPT_COLUMNS = (\"speaker\", \"start\", \"stop\", \"utterance\", \"confidence\")\n",
    "        TRANSCRIPT_DTYPES = (str, np.float64, np.float64, str, object)\n",
    "        \n",
    "        df = pd.DataFrame.from_records(json_transcript['transcript'], index=\"turn_id\")\n",
    "        df = self.replace_speaker_channel_with_user_id(df)\n",
    "        \n",
    "        assert set(df.columns) == set(TRANSCRIPT_COLUMNS)\n",
    "        \n",
    "        for c, d in zip(TRANSCRIPT_COLUMNS, TRANSCRIPT_DTYPES):\n",
    "            df[c] = df[c].astype(d)\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(\"Conversation is empty. Did you pass a dict or list?\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def baseline_to_natural_turn(self, baseline_df, config):\n",
    "        return collapse_transcript_turns(Transcript(baseline_df, config))\n",
    "\n",
    "    def save_transcripts_to_local(self, transcript_obj, model_label):\n",
    "        # update paths to reflect local save file directory\n",
    "        baseline_filename = f'{self.save_dir}/{self.conversation_id}_baseline.csv'\n",
    "        natural_turn_filename = f'{self.save_dir}/{self.conversation_id}_{model_label}.csv'\n",
    "        edit_history_filename = f'{self.save_dir}/{self.conversation_id}_{model_label}_edit-history.csv'\n",
    "\n",
    "        transcript_obj.baseline.to_csv(baseline_filename)\n",
    "        transcript_obj.transcript.to_csv(natural_turn_filename)\n",
    "        transcript_obj.edit_history.to_csv(edit_history_filename)\n",
    "        \n",
    "    def replace_speaker_channel_with_user_id(self, df):\n",
    "        \"\"\"Use any JSON file with the following structure to map stereo channels (L/R) to speaker IDs:\n",
    "            metadata: full JSON object\n",
    "            metadata['speakers']: 'speakers' key is a list, each entry is a dict with 'channel' and 'user_id' keys\n",
    "            metadata['speakers'][0]['channel']: takes values 'L' or 'R'\n",
    "            metadata['speakers'][0]['user_id']: unique identifier for a speaker\n",
    "        \"\"\"\n",
    "        metadata = json.load(open(self.metadata_path, 'r'))\n",
    "        \n",
    "        # Create mapping from channel to user_id\n",
    "        speaker_mapping = {speaker['channel']: speaker['user_id'] for speaker in metadata['speakers']}\n",
    "        \n",
    "        # Replace R/L 'speaker' values with user_id values\n",
    "        df['speaker'] = df['speaker'].map(speaker_mapping)\n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f286bfe-acd8-4417-8b4a-8eb601a87cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42d99fff-daee-41bc-ba4a-55b6a787e51d processing...\n",
      "473435df-b97f-4c9f-a8e2-8e3fc66a8902 processing...\n",
      "5d7dc5a5-8dbe-4fb0-bf59-2d53f0ce3b65 processing...\n",
      "6cc56ecc-d29c-4bb3-bbd9-c67236c15b0c processing...\n",
      "7fc59ebb-a980-4df1-9d39-f15ae25f3f27 processing...\n",
      "a003874c-1d39-4924-857f-94a865951ae9 processing...\n",
      "afa4d802-a9ed-4b0b-a607-b5f16d899275 processing...\n",
      "cc7a5173-9c79-4773-83dc-0d9177bcc524 processing...\n",
      "e12fed95-8f11-4255-b8c7-f5c0346b8e59 processing...\n",
      "f5ced37a-1596-4e77-ab1d-dae5e084384d processing...\n"
     ]
    }
   ],
   "source": [
    "for conversation_id in sorted(conversation_ids[:10]):\n",
    "    print(f'{conversation_id} processing...')\n",
    "    formatter = TranscriptFormatter(\n",
    "        conversation_id=conversation_id, \n",
    "        save_dir=\"data/new_transcripts\"\n",
    "    )\n",
    "    try:\n",
    "        formatted_json = formatter.construct_conversation_transcript()\n",
    "    except Exception as e:\n",
    "        print(f'Error for convo {conversation_id}: {str(e)}')\n",
    "        continue\n",
    "        \n",
    "    baseline_df = formatter.json_to_baseline_df(formatted_json)\n",
    "    transcript_obj = formatter.baseline_to_natural_turn(baseline_df, config=natural_turn)\n",
    "    \n",
    "    # save files\n",
    "    # adjust model_label as needed. here we use the natural_turn max_pause setting to disambiguate model variants.\n",
    "    max_pause = int(natural_turn.max_pause * 1000) # max_pause to milliseconds\n",
    "    model_label = f'natural_turn-{max_pause}'\n",
    "    formatter.save_transcripts_to_local(transcript_obj, model_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0a5ed-beee-4ea2-a38f-5aee5721e22f",
   "metadata": {},
   "source": [
    "### Concat all natural_turns transcripts into a single data frame, save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6806e354-616d-44ea-9ef3-5689f3e16ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_transcripts_from_local(conversation_ids, max_pause, file_path_template):\n",
    "    \"\"\"Convenience function to concatenate all processed transcripts into a single Pandas data frame.\"\"\"\n",
    "    all_dfs = []\n",
    "    for i, conversation_id in enumerate(conversation_ids):\n",
    "        csv_path = file_path_template.format(conversation_id=conversation_id, max_pause=max_pause)\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df['conversation_id'] = conversation_id\n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"File not found: {csv_path}\")\n",
    "            print(str(e))\n",
    "    concatenated_df = pd.concat(all_dfs, axis=0, ignore_index=True)\n",
    "    return concatenated_df\n",
    "\n",
    "# Usage \n",
    "\n",
    "# Note: Adjust file_path_template to concatenate baseline or edit_history instead of NT transcripts\n",
    "conv_ids = sorted(conversation_ids[:10])\n",
    "max_pause = 1500\n",
    "file_path_template = '{conversation_id}_natural_turn-{max_pause}.csv'\n",
    "save_path = f'aws-2024-natural_turn-{max_pause}--candor.csv'\n",
    "natural_turn_df = concatenate_transcripts_from_local(conv_ids, max_pause, file_path_template)\n",
    "natural_turn_df.to_csv(save_path, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82566cc8-1be1-4110-83fc-bebcba74b9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
